package com.example.chatlog.service.impl;

import com.example.chatlog.dto.ChatRequest;
import com.example.chatlog.dto.RequestBody;
import com.example.chatlog.enums.ModelProvider;
import com.example.chatlog.service.AiService;
import com.example.chatlog.service.LogApiService;
import com.example.chatlog.service.ModelConfigService;
import com.example.chatlog.utils.SchemaHint;
import com.example.chatlog.utils.QueryTemplates;
import com.example.chatlog.utils.PromptTemplate;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.node.ObjectNode;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.ai.chat.client.advisor.MessageChatMemoryAdvisor;
import org.springframework.ai.chat.memory.ChatMemory;
import org.springframework.ai.chat.memory.MessageWindowChatMemory;
import org.springframework.ai.chat.memory.repository.jdbc.JdbcChatMemoryRepository;
import org.springframework.ai.chat.messages.SystemMessage;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.prompt.ChatOptions;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.content.Media;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.core.ParameterizedTypeReference;
import org.springframework.stereotype.Service;
import org.springframework.util.MimeTypeUtils;
import org.springframework.web.client.RestClient;
import org.springframework.web.multipart.MultipartFile;
import java.time.LocalDateTime;
import java.time.format.DateTimeFormatter;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

@Service
public class AiServiceImpl implements AiService {
  // L∆∞u tr·ªØ th√¥ng tin mapping c·ªßa Elasticsearch index ƒë·ªÉ tr√°nh g·ªçi l·∫°i nhi·ªÅu l·∫ßn
  private static String fieldLog;

  // Client ƒë·ªÉ giao ti·∫øp v·ªõi AI model (Spring AI)
  private final ChatClient chatClient;

  @Autowired
  private LogApiService logApiService;
  
  @Autowired
  private ModelConfigService modelConfigService;
  
  @Autowired
  @Qualifier("openRouterChatClient")
  private RestClient openRouterClient;

  /**
   * T·∫°o chu·ªói th√¥ng tin ng√†y th√°ng cho system message v·ªõi c√°c bi·ªÉu th·ª©c th·ªùi gian t∆∞∆°ng ƒë·ªëi c·ªßa Elasticsearch
   * @param now Th·ªùi ƒëi·ªÉm hi·ªán t·∫°i (real-time)
   * @return Chu·ªói ch·ª©a th√¥ng tin v·ªÅ c√°ch s·ª≠ d·ª•ng bi·ªÉu th·ª©c th·ªùi gian t∆∞∆°ng ƒë·ªëi c·ªßa Elasticsearch
   */
  private String generateDateContext(LocalDateTime now) {
    return String.format("""
                CURRENT TIME CONTEXT (Vietnam timezone +07:00):
                - Current exact time: %s (+07:00)
                - Current date: %s
                
                PREFERRED TIME QUERY METHOD - Use Elasticsearch relative time expressions:
                - "5 ph√∫t qua, 5 ph√∫t tr∆∞·ªõc, 5 minutes ago", "last 5 minutes" ‚Üí {"gte": "now-5m"}
                - "1 gi·ªù qua, 1 gi·ªù tr∆∞·ªõc, 1 hour ago", "last 1 hour" ‚Üí {"gte": "now-1h"}
                - "24 gi·ªù qua, 24 gi·ªù tr∆∞·ªõc, 24 hours ago", "last 24 hours" ‚Üí {"gte": "now-24h"}
                - "1 tu·∫ßn qua, 1 tu·∫ßn tr∆∞·ªõc, 1 week ago", "7 ng√†y qua, 7 ng√†y tr∆∞·ªõc, 7 days ago", "last week" ‚Üí {"gte": "now-7d"}
                - "1 th√°ng qua, 1 th√°ng tr∆∞·ªõc, 1 month ago", "last month" ‚Üí {"gte": "now-30d"}
                
                SPECIFIC DATE RANGES (when exact dates mentioned):
                - "h√¥m nay, h√¥m nay, today" ‚Üí {"gte": "now/d"}
                - "h√¥m qua, h√¥m qua, yesterday" ‚Üí {"gte": "now-1d/d"}
                - Specific date like "ng√†y 15-09" ‚Üí {"gte": "2025-09-15T00:00:00.000+07:00", "lte": "2025-09-15T23:59:59.999+07:00"}
                
                ADVANTAGES of "now-Xh/d/m" format:
                - More efficient than absolute timestamps
                - Automatically handles timezone
                - Elasticsearch native time calculations
                - Always relative to query execution time
                """,
        now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")),
        now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd"))
    );
  }

  /**
   * Constructor kh·ªüi t·∫°o AiServiceImpl v·ªõi ChatClient v√† memory
   * @param builder ChatClient.Builder ƒë·ªÉ x√¢y d·ª±ng client AI
   * @param jdbcChatMemoryRepository Repository l∆∞u tr·ªØ l·ªãch s·ª≠ chat
   */
  public AiServiceImpl(ChatClient.Builder builder,  JdbcChatMemoryRepository jdbcChatMemoryRepository) {

    // Kh·ªüi t·∫°o memory ƒë·ªÉ l∆∞u tr·ªØ l·ªãch s·ª≠ chat c·ªßa ng∆∞·ªùi d√πng (t·ªëi ƒëa 50 tin nh·∫Øn)
    ChatMemory chatMemory = MessageWindowChatMemory.builder()
        .chatMemoryRepository(jdbcChatMemoryRepository)
        .maxMessages(50)
        .build();

    // X√¢y d·ª±ng ChatClient v·ªõi memory advisor ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán
    this.chatClient = builder
        .defaultAdvisors(MessageChatMemoryAdvisor.builder(chatMemory).build())
        .build();

  }

  /**
   * H√†m ch√≠nh x·ª≠ l√Ω y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng
   * Quy tr√¨nh 3 b∆∞·ªõc:
   * 1. Ph√¢n t√≠ch c√¢u h·ªèi v√† t·∫°o Elasticsearch query (b·∫Øt bu·ªôc cho t·∫•t c·∫£ request)
   * 2. Th·ª±c hi·ªán t√¨m ki·∫øm Elasticsearch v√† l·∫•y d·ªØ li·ªáu log
   * 3. T√≥m t·∫Øt v√† tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n
   *
   * @param sessionId ID phi√™n chat ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh
   * @param chatRequest Y√™u c·∫ßu t·ª´ ng∆∞·ªùi d√πng
   * @return C√¢u tr·∫£ l·ªùi ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω
   */
  @Override
  public String handleRequest(Long sessionId, ChatRequest chatRequest) {

  String content = "";
  RequestBody requestBody;

    // In ra th√¥ng tin c·∫•u h√¨nh OpenAI tr∆∞·ªõc khi g·ªçi
    String openaiUrl = System.getenv("OPENAI_API_URL");
    String openaiApiKey = System.getenv("OPENAI_API_KEY");
    String model = "gpt-4o-mini";

    try {
      String baseUrl = System.getProperty("spring.ai.openai.base-url");
      String apiKey = System.getProperty("spring.ai.openai.api-key");
    } catch (Exception ex) {
      System.out.println("[SpringAI] Kh√¥ng l·∫•y ƒë∆∞·ª£c base-url/api-key ");
    }

    // B∆∞·ªõc 1: T·∫°o system message h∆∞·ªõng d·∫´n AI ph√¢n t√≠ch y√™u c·∫ßu
    // L·∫•y ng√†y hi·ªán t·∫°i ƒë·ªÉ AI c√≥ th·ªÉ x·ª≠ l√Ω c√°c y√™u c·∫ßu v·ªÅ th·ªùi gian ch√≠nh x√°c
    LocalDateTime now = LocalDateTime.now();
    String dateContext = generateDateContext(now);

    // C√°ch 2: S·ª≠ d·ª•ng SystemPromptTemplate v·ªõi c√°c placeholder th√¥ng qua PromptConverter
    // Kh√¥ng th·ªÉ s·ª≠ d·ª•ng Map.of v·ªõi h∆°n 10 c·∫∑p key-value, chuy·ªÉn sang s·ª≠ d·ª•ng HashMap
    Map<String, String> params = new HashMap<>();
    params.put("name", "ElasticSearch Expert");
    params.put("role", "chuy√™n gia");
    params.put("expertise", "Elasticsearch Query DSL v√† ph√¢n t√≠ch log b·∫£o m·∫≠t");
    params.put("style", "chuy√™n nghi·ªáp v√† ch√≠nh x√°c");
    params.put("constraints", "Ch·ªâ tr·∫£ v·ªÅ JSON query, kh√¥ng gi·∫£i th√≠ch");
    params.put("dateContext", dateContext);
    params.put("fieldMappings", SchemaHint.getSchemaHint());
    params.put("categoryGuides", SchemaHint.getCategoryGuides());
    params.put("roleNormalizationRules", SchemaHint.getRoleNormalizationRules());
    params.put("exampleQueries", String.join("\n\n", 
        SchemaHint.getNetworkTrafficExamples(),
        SchemaHint.getIPSSecurityExamples(),
        SchemaHint.getAdminRoleExample(),
        SchemaHint.getGeographicExamples(),
        SchemaHint.getFirewallRuleExamples(),
        SchemaHint.getCountingExamples(),
        SchemaHint.getQuickPatterns()
    ));
    params.put("currentTime", now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")));
    params.put("indexSchema", SchemaHint.getSchemaHint());
    params.put("complexityLevel", "Advanced - H·ªó tr·ª£ nested aggregations v√† bucket selectors");
    params.put("maxSize", "1000");
    
    // S·ª≠ d·ª•ng QueryPromptTemplate: ƒë∆∞a to√†n b·ªô th∆∞ vi·ªán + v√≠ d·ª• ƒë·ªông (n·∫øu c√≥)
    Map<String, Object> dynamicInputs = new HashMap<>();
    String queryPrompt = com.example.chatlog.utils.QueryPromptTemplate.createQueryGenerationPromptWithAllTemplates(
        chatRequest.message(),
        dateContext,
        SchemaHint.getSchemaHint(),
        SchemaHint.getRoleNormalizationRules(),
        dynamicInputs
    );
    SystemMessage systemMessage = new SystemMessage(queryPrompt);


    List<String> schemaHints = SchemaHint.allSchemas();
    String schemaContext = String.join("\n\n", schemaHints);
    UserMessage schemaMsg = new UserMessage("Available schema hints:\n" + schemaContext);
    // Provide a single sample log to help AI infer fields and structure
    UserMessage sampleLogMsg = new UserMessage("SAMPLE LOG (for inference):\n" + SchemaHint.examplelog());

    UserMessage userMessage = new UserMessage(chatRequest.message());

    System.out.println("----------------------------------------------------------");
    Prompt prompt = new Prompt(List.of(systemMessage, schemaMsg, sampleLogMsg, userMessage));

    // C·∫•u h√¨nh ChatClient v·ªõi temperature = 0 ƒë·ªÉ c√≥ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh v√† tu√¢n th·ªß strict
    ChatOptions chatOptions = ChatOptions.builder()
        .temperature(0.0D)
        .build();

    // G·ªçi AI ƒë·ªÉ ph√¢n t√≠ch v√† t·∫°o request body
    try {
      // S·ª¨A: S·ª≠ d·ª•ng conversationId ri√™ng cho query generation ƒë·ªÉ tr√°nh memory contamination
      String queryConversationId = sessionId + "_query_generation";
      
      System.out.println("[AiServiceImpl] ü§ñ ƒêang g·ªçi AI ƒë·ªÉ t·∫°o Elasticsearch query...");
      requestBody =  chatClient
          .prompt(prompt)
          .options(chatOptions)
          .advisors(advisorSpec -> advisorSpec.param(
              ChatMemory.CONVERSATION_ID, queryConversationId
          ))
          .call()
          .entity(new ParameterizedTypeReference<>() {
          });

      // Log response tr·∫£ v·ªÅ t·ª´ OpenAI
      System.out.println("[SpringAI] --- HTTP RESPONSE ---");
      // Kh√¥ng l·∫•y ƒë∆∞·ª£c status code v√† header tr·ª±c ti·∫øp, ch·ªâ log body
      System.out.println("Body:");
      System.out.println(requestBody);
//      System.out.println("---------------------------");
    } catch (Exception e) {
      // Ki·ªÉm tra lo·∫°i l·ªói v√† x·ª≠ l√Ω ph√π h·ª£p
      if (e.getMessage() != null) {
        if (e.getMessage().contains("503") || e.getMessage().contains("upstream connect error")) {
          System.out.println("[AiServiceImpl] ‚ö†Ô∏è AI Service t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng (HTTP 503). ƒêang th·ª≠ l·∫°i...");
          return "‚ö†Ô∏è **AI Service t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng**\n\n" +
                 "L·ªói k·∫øt n·ªëi t·∫°m th·ªùi v·ªõi AI service. Vui l√≤ng th·ª≠ l·∫°i sau v√†i gi√¢y.\n\n" +
                 "**Chi ti·∫øt:** " + e.getMessage() + "\n\n" +
                 "üí° **G·ª£i √Ω:** H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông retry. N·∫øu v·∫•n ƒë·ªÅ ti·∫øp t·ª•c, vui l√≤ng li√™n h·ªá admin.";
        } else if (e.getMessage().contains("401") || e.getMessage().contains("Unauthorized")) {
          System.out.println("[AiServiceImpl] ‚ùå L·ªói x√°c th·ª±c API key: " + e.getMessage());
          return "‚ùå **L·ªói x√°c th·ª±c API**\n\n" +
                 "API key kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n.\n\n" +
                 "**Chi ti·∫øt:** " + e.getMessage() + "\n\n" +
                 "üí° **G·ª£i √Ω:** Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u h√¨nh API key.";
        } else if (e.getMessage().contains("429") || e.getMessage().contains("rate limit")) {
          System.out.println("[AiServiceImpl] ‚ö†Ô∏è Rate limit exceeded: " + e.getMessage());
          return "‚ö†Ô∏è **Rate Limit Exceeded**\n\n" +
                 "ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n s·ªë l∆∞·ª£ng request. Vui l√≤ng ch·ªù v√†i ph√∫t tr∆∞·ªõc khi th·ª≠ l·∫°i.\n\n" +
                 "**Chi ti·∫øt:** " + e.getMessage() + "\n\n" +
                 "üí° **G·ª£i √Ω:** H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông retry sau m·ªôt kho·∫£ng th·ªùi gian.";
        }
      }
      
      System.out.println("[AiServiceImpl] ‚ùå ERROR: Failed to parse AI response: " + e.getMessage());
      return "‚ùå **AI Service Error**\n\n" +
             "Kh√¥ng th·ªÉ k·∫øt n·ªëi t·ªõi AI service ho·∫∑c ph·∫£n h·ªìi kh√¥ng h·ª£p l·ªá.\n\n" +
             "**Chi ti·∫øt:** " + e.getMessage() + "\n\n" +
             "üí° **G·ª£i √Ω:** Vui l√≤ng th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá admin n·∫øu v·∫•n ƒë·ªÅ ti·∫øp t·ª•c.";
    }

    // ƒê·∫£m b·∫£o query lu√¥n l√† 1 (b·∫Øt bu·ªôc t√¨m ki·∫øm)
    if (requestBody.getQuery() != 1) {
      System.out.println("[AiServiceImpl] Setting query=1 (was " + requestBody.getQuery() + ")");
      requestBody.setQuery(1);
    }

    System.out.println("THong tin quey: "+requestBody.getQuery());
    System.out.println("[AiServiceImpl] Generated query body: " + requestBody.getBody());
    System.out.println("[AiServiceImpl] Using current date context: " + now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd")));

    String fixedQuery = requestBody.getBody(); // Gi√° tr·ªã m·∫∑c ƒë·ªãnh

    // Validation: Ki·ªÉm tra xem body c√≥ ph·∫£i l√† JSON query hay kh√¥ng
    if (requestBody.getBody() != null) {

      String flg = checkBodyFormat(requestBody);
      System.out.println("flg: " + flg);
      if (flg != null)
      {
        return flg;
      }

      System.out.println("requestBody: " + requestBody);
      System.out.println("chatRequest: " + chatRequest);
      String[] result = getLogData(requestBody, chatRequest);
      content = result[0];
      fixedQuery = result[1];

      System.out.println("content: " + content);

      // Check if content is actually an error message (starts with ‚ùå)
      if (content != null && content.startsWith("‚ùå")) {
        // Return error immediately without further processing
        return content;
      }
      
      // Check if Elasticsearch returned empty results
      if (content != null && isEmptyElasticsearchResult(content)) {
        System.out.println("[AiServiceImpl] Elasticsearch returned no data, continuing with AI processing");
        // Kh√¥ng tr·∫£ v·ªÅ l·ªói tr·ª±c ti·∫øp, ƒë·ªÉ AI x·ª≠ l√Ω tr∆∞·ªùng h·ª£p kh√¥ng c√≥ d·ªØ li·ªáu
      }
    }

    // B∆∞·ªõc 3: T√≥m t·∫Øt k·∫øt qu·∫£ v√† tr·∫£ l·ªùi ng∆∞·ªùi d√πng
    return getAiResponse(sessionId,chatRequest,content, fixedQuery);
  }

  /**
   * Ki·ªÉm tra v√† s·ª≠a ƒë·ªãnh d·∫°ng ph·∫ßn th√¢n (body) JSON c·ªßa truy v·∫•n
   * - C√¢n b·∫±ng d·∫•u ngo·∫∑c nh·ªçn n·∫øu b·ªã l·ªách
   * - X√°c th·ª±c ph·∫£i c√≥ √≠t nh·∫•t m·ªôt trong hai tr∆∞·ªùng: "query" ho·∫∑c "aggs"
   * - T·∫°o l·∫°i RequestBody n·∫øu JSON ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông s·ª≠a ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n
   *
   * @param requestBody ƒê·ªëi t∆∞·ª£ng ch·ª©a JSON truy v·∫•n do AI t·∫°o ra
   * @return null n·∫øu h·ª£p l·ªá; tr·∫£ v·ªÅ chu·ªói th√¥ng b√°o l·ªói n·∫øu kh√¥ng h·ª£p l·ªá
   */
  private String checkBodyFormat(RequestBody requestBody){
    // Ch·ªâ ki·ªÉm tra h·ª£p l·ªá, kh√¥ng t·ª± s·ª≠a JSON

    try {
      JsonNode jsonNode = new com.fasterxml.jackson.databind.ObjectMapper().readTree(requestBody.getBody());

      // Validate that it's a proper Elasticsearch query
      if (!jsonNode.has("query") && !jsonNode.has("aggs")) {
        System.out.println("[AiServiceImpl] ERROR: Missing 'query' or 'aggs' field!");
        return "‚ùå AI model tr·∫£ v·ªÅ query kh√¥ng h·ª£p l·ªá. C·∫ßn c√≥ 'query' ho·∫∑c 'aggs' field.";
      }

    } catch (Exception e) {
      System.out.println("[AiServiceImpl] ERROR: Invalid JSON format from AI!");
      System.out.println("[AiServiceImpl] Expected: JSON object with 'query' or 'aggs' field");
      System.out.println("[AiServiceImpl] Received: " + requestBody.getBody());
      System.out.println("[AiServiceImpl] Error details: " + e.getMessage());
      return "‚ùå AI model tr·∫£ v·ªÅ format kh√¥ng ƒë√∫ng. C·∫ßn JSON query (m·ªôt object duy nh·∫•t), nh·∫≠n ƒë∆∞·ª£c: " + requestBody.getBody();
    }

    return null;
  }


  /**
   * Phi√™n b·∫£n ƒë∆°n gi·∫£n c·ªßa getLogData v·ªõi retry khi g·∫∑p l·ªói 400
   * @param requestBody Ch·ª©a JSON query t·ª´ AI
   * @param chatRequest Y√™u c·∫ßu g·ªëc c·ªßa user
   * @return [content, query] - n·ªôi dung t·ª´ ES v√† query ƒë√£ s·ª≠ d·ª•ng
   */
  private String[] getLogData(RequestBody requestBody, ChatRequest chatRequest) {
    String query = requestBody.getBody();

    // First try to fix common query structure issues
    String fixedQuery = fixQueryStructure(query);
    if (!fixedQuery.equals(query)) {
      System.out.println("[AiServiceImpl] üîß Query structure was automatically fixed");
      query = fixedQuery; // Use the fixed query
    }

    // Validate query syntax before sending to Elasticsearch
    String validationError = validateQuerySyntax(query);
    if (validationError != null) {
      System.out.println("[AiServiceImpl] Query validation failed: " + validationError);
      return new String[]{
          "‚ùå **Query Validation Error**\n\n" +
              "Query c√≥ c√∫ ph√°p kh√¥ng h·ª£p l·ªá tr∆∞·ªõc khi g·ª≠i ƒë·∫øn Elasticsearch.\n\n" +
              "**L·ªói validation:** " + validationError + "\n\n" +
              "üí° **G·ª£i √Ω:** Vui l√≤ng th·ª≠ c√¢u h·ªèi kh√°c ho·∫∑c ki·ªÉm tra l·∫°i c·∫•u tr√∫c query.",
          query
      };
    }

    try {
      System.out.println("[AiServiceImpl] Sending query to Elasticsearch: " + query);
      String content = logApiService.search("logs-fortinet_fortigate.log-default*", query);
      System.out.println("[AiServiceImpl] Elasticsearch response received successfully");
      return new String[]{content, query};
    }
    catch (Exception e) {
      System.out.println("[AiServiceImpl] ERROR: Log API returned an error! " + e.getMessage());

      // Parse error details t·ª´ Elasticsearch
      String errorDetails = extractElasticsearchError(e.getMessage());
      System.out.println("[AiServiceImpl] Parsed error details: " + errorDetails);

      // N·∫øu l√† l·ªói 400 Bad Request, th·ª≠ s·ª≠a query b·∫±ng AI v√† retry m·ªôt l·∫ßn
      if (e.getMessage().contains("400") || e.getMessage().contains("Bad Request") ||
          e.getMessage().contains("parsing_exception") || e.getMessage().contains("illegal_argument_exception")) {

        System.out.println("[AiServiceImpl] üîÑ ƒêang th·ª≠ s·ª≠a query v·ªõi AI v√† retry...");

        try {
          // L·∫•y field mapping v√† t·∫°o comparison prompt v·ªõi error details
          String allFields = SchemaHint.getSchemaHint();
          String prevQuery = requestBody.getBody();
          String userMess = chatRequest.message();

          // C·∫£i thi·ªán prompt v·ªõi error details c·ª• th·ªÉ
          String enhancedPrompt = PromptTemplate.getComparisonPrompt(
              allFields, prevQuery, userMess, generateDateContext(LocalDateTime.now())
          ) + "\n\nIMPORTANT: The previous query failed with this error:\n" + errorDetails + 
              "\nPlease fix the specific issue mentioned in the error and generate a corrected Elasticsearch query.";

          Prompt comparePrompt = new Prompt(
              new SystemMessage(enhancedPrompt),
              new UserMessage("Fix this query error: " + errorDetails + " | User request: " + userMess + " | Failed query: " + prevQuery)
          );

          // Provider for retry flow: default ChatClient (OpenAI)
          // Gi·ªØ temperature = 0.0 ƒë·ªÉ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh v√† b√°m s√°t l·ªói c·∫ßn s·ª≠a
          ChatOptions retryChatOptions = ChatOptions.builder()
              .temperature(0.0D)
              .build();

          // G·ªçi AI ƒë·ªÉ t·∫°o query m·ªõi v·ªõi isolate memory
          String retryConversationId = "retry_" + System.currentTimeMillis();
          String newQuery;
          
          try {
            // First try to get as RequestBody (normal flow)
            RequestBody newRequestBody = chatClient.prompt(comparePrompt)
                .options(retryChatOptions)
                .advisors(advisorSpec -> advisorSpec.param(
                    ChatMemory.CONVERSATION_ID, retryConversationId
                ))
                .call()
                .entity(new ParameterizedTypeReference<>() {});

            // ƒê·∫£m b·∫£o query lu√¥n l√† 1
            if (newRequestBody.getQuery() != 1) {
              newRequestBody.setQuery(1);
            }
            newQuery = newRequestBody.getBody();
          } catch (Exception parseException) {
            System.out.println("[AiServiceImpl] Failed to parse as RequestBody, trying raw JSON: " + parseException.getMessage());
            
            // If RequestBody parsing fails, try to get raw JSON response
            String rawResponse = chatClient.prompt(comparePrompt)
                .options(retryChatOptions)
                .advisors(advisorSpec -> advisorSpec.param(
                    ChatMemory.CONVERSATION_ID, retryConversationId
                ))
                .call()
                .content();
            
            // Clean and validate the raw JSON response
            newQuery = rawResponse.trim();
            
            // Remove any markdown code blocks if present
            if (newQuery.startsWith("```json")) {
              newQuery = newQuery.substring(7);
            }
            if (newQuery.endsWith("```")) {
              newQuery = newQuery.substring(0, newQuery.length() - 3);
            }
            newQuery = newQuery.trim();
            
            // Validate that it's valid JSON
            try {
              new com.fasterxml.jackson.databind.ObjectMapper().readTree(newQuery);
              System.out.println("[AiServiceImpl] Successfully parsed raw JSON response");
            } catch (Exception jsonException) {
              System.out.println("[AiServiceImpl] Raw response is not valid JSON: " + jsonException.getMessage());
              throw new RuntimeException("AI returned invalid JSON: " + newQuery, jsonException);
            }
          }
          System.out.println("[AiServiceImpl] üîß Generated new query with error fix: " + newQuery);

          // Ki·ªÉm tra xem query m·ªõi c√≥ kh√°c query c≈© kh√¥ng
          if (newQuery.equals(prevQuery)) {
            System.out.println("[AiServiceImpl] WARNING: New query is identical to failed query");
            return new String[]{
                "‚ùå **Elasticsearch Error (Same Query Generated)**\n\n" +
                    "AI t·∫°o ra query gi·ªëng h·ªát v·ªõi query ƒë√£ l·ªói.\n\n" +
                    "**L·ªói g·ªëc:** " + errorDetails + "\n\n" +
                    "üí° **G·ª£i √Ω:** Vui l√≤ng th·ª≠ c√¢u h·ªèi kh√°c v·ªõi c√°ch di·ªÖn ƒë·∫°t kh√°c.",
                query
            };
          }

          // Retry v·ªõi query m·ªõi
          System.out.println("[AiServiceImpl] üîÑ ƒêang th·ª≠ l·∫°i v·ªõi query ƒë√£ s·ª≠a...");
          String retryContent = logApiService.search("logs-fortinet_fortigate.log-default*", newQuery);
          System.out.println("[AiServiceImpl] ‚úÖ Retry successful with corrected query");
          return new String[]{retryContent, newQuery};

        } catch (Exception retryE) {
          System.out.println("[AiServiceImpl] Retry also failed: " + retryE.getMessage());
          
          // Determine if it's a parsing error or Elasticsearch error
          String retryErrorDetails;
          if (retryE.getMessage().contains("Cannot deserialize") || retryE.getMessage().contains("MismatchedInputException")) {
            retryErrorDetails = "AI Response Parsing Error - AI returned invalid format";
          } else {
            retryErrorDetails = extractElasticsearchError(retryE.getMessage());
          }
          
          return new String[]{
              "‚ùå **Elasticsearch Error (After Retry)**\n\n" +
                  "Query ban ƒë·∫ßu l·ªói v√† query ƒë∆∞·ª£c s·ª≠a c≈©ng kh√¥ng th√†nh c√¥ng.\n\n" +
                  "**L·ªói ban ƒë·∫ßu:** " + errorDetails + "\n\n" +
                  "**L·ªói sau retry:** " + retryErrorDetails + "\n\n" +
                  "üí° **G·ª£i √Ω:** Vui l√≤ng th·ª≠ c√¢u h·ªèi kh√°c ho·∫∑c ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu.",
              query
          };
        }
      }

      // V·ªõi c√°c l·ªói kh√°c (kh√¥ng ph·∫£i 400), tr·∫£ l·ªói tr·ª±c ti·∫øp
      return new String[]{
          "‚ùå **Elasticsearch Error**\n\n" +
              "Kh√¥ng th·ªÉ th·ª±c hi·ªán truy v·∫•n Elasticsearch.\n\n" +
              "**Chi ti·∫øt l·ªói:** " + errorDetails + "\n\n" +
              "üí° **G·ª£i √Ω:** Ki·ªÉm tra l·∫°i c√¢u h·ªèi ho·∫∑c li√™n h·ªá admin.",
          query
      };
    }
  }

  /**
   * Ki·ªÉm tra xem k·∫øt qu·∫£ t·ª´ Elasticsearch c√≥ r·ªóng kh√¥ng
   * @param elasticsearchResponse JSON response t·ª´ Elasticsearch
   * @return true n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu, false n·∫øu c√≥ d·ªØ li·ªáu
   */
  private boolean isEmptyElasticsearchResult(String elasticsearchResponse) {
    try {
      JsonNode jsonNode = new com.fasterxml.jackson.databind.ObjectMapper().readTree(elasticsearchResponse);
      
      boolean hasHits = false;
      if (jsonNode.has("hits")) {
        JsonNode hitsNode = jsonNode.get("hits");
        if (hitsNode.has("total")) {
          JsonNode totalNode = hitsNode.get("total");
          if (totalNode.has("value") && totalNode.get("value").asLong() > 0) {
            hasHits = true;
          }
        }
        if (!hasHits && hitsNode.has("hits")) {
          JsonNode hitsArrayNode = hitsNode.get("hits");
          if (hitsArrayNode.isArray() && hitsArrayNode.size() > 0) {
            hasHits = true;
          }
        }
      }
      
      boolean hasAggregations = jsonNode.has("aggregations");
      
      // No-data ONLY when there are no hits AND no aggregations at all
      return !hasHits && !hasAggregations;
      
    } catch (Exception e) {
      System.out.println("[AiServiceImpl] Error parsing Elasticsearch response for empty check: " + e.getMessage());
      return false; // If parse fails, do not block; let AI format
    }
  }

  /**
   * Parse error message t·ª´ Elasticsearch ƒë·ªÉ l·∫•y th√¥ng tin chi ti·∫øt
   * @param errorMessage Raw error message
   * @return Parsed error details
   */
  private String extractElasticsearchError(String errorMessage) {
    // Extract common Elasticsearch error patterns
    if (errorMessage.contains("parsing_exception")) {
      return "Query syntax error - Invalid JSON structure or field mapping";
    } else if (errorMessage.contains("illegal_argument_exception")) {
      return "Invalid argument - Check field names and aggregation syntax";
    } else if (errorMessage.contains("No mapping found")) {
      return "Field mapping error - Field does not exist in index";
    } else if (errorMessage.contains("400 Bad Request")) {
      return "Bad Request - Query structure or field validation failed";
    } else if (errorMessage.contains("index_not_found_exception")) {
      return "Index not found - Check index name and existence";
    } else {
      // Return first 200 characters c·ªßa error message
      return errorMessage.length() > 200 ? errorMessage.substring(0, 200) + "..." : errorMessage;
    }
  }

  /**
   * Validate Elasticsearch query syntax before sending to Elasticsearch
   * @param query JSON query string
   * @return null if valid, error message if invalid
   */
  private String validateQuerySyntax(String query) {
    try {
      // Parse JSON to check syntax
      JsonNode jsonNode = new com.fasterxml.jackson.databind.ObjectMapper().readTree(query);
      
      // Check for required fields
      if (!jsonNode.has("query") && !jsonNode.has("aggs")) {
        return "Query must contain either 'query' or 'aggs' field";
      }
      
      // Check for common syntax issues
      if (jsonNode.has("query")) {
        JsonNode queryNode = jsonNode.get("query");
        
        // Check if aggs is incorrectly placed inside query instead of at root level
        if (queryNode.has("aggs")) {
          return "Aggregations must be at root level, not inside query. Move 'aggs' outside of 'query'.";
        }
        
        if (queryNode.has("bool")) {
          JsonNode boolNode = queryNode.get("bool");
          
          // Check if aggs is incorrectly placed inside bool
          if (boolNode.has("aggs")) {
            return "Aggregations must be at root level, not inside bool query. Move 'aggs' outside of 'query'.";
          }
          
          if (boolNode.has("filter")) {
            JsonNode filterNode = boolNode.get("filter");
            if (!filterNode.isArray()) {
              return "Bool filter must be an array";
            }
            
            // Check each filter element
            for (JsonNode filter : filterNode) {
              if (filter.has("aggs")) {
                return "Aggregations cannot be inside filter. Move 'aggs' to root level.";
              }
            }
          }
          
          if (boolNode.has("must")) {
            JsonNode mustNode = boolNode.get("must");
            if (!mustNode.isArray()) {
              return "Bool must must be an array";
            }
          }
          
          if (boolNode.has("should")) {
            JsonNode shouldNode = boolNode.get("should");
            if (!shouldNode.isArray()) {
              return "Bool should must be an array";
            }
          }
        }
      }
      
      // Check aggregations structure
      if (jsonNode.has("aggs")) {
        JsonNode aggsNode = jsonNode.get("aggs");
        if (!aggsNode.isObject()) {
          return "Aggregations must be an object";
        }
      }
      
      // Check for size parameter
      if (jsonNode.has("size")) {
        JsonNode sizeNode = jsonNode.get("size");
        if (!sizeNode.isNumber()) {
          return "Size parameter must be a number";
        }
      }
      
      return null; // Valid query
      
    } catch (Exception e) {
      return "Invalid JSON syntax: " + e.getMessage();
    }
  }

  /**
   * Attempt to fix common Elasticsearch query structure issues
   * @param query JSON query string
   * @return Fixed query string or original if no fixes needed
   */
  private String fixQueryStructure(String query) {
    try {
      ObjectMapper mapper = new ObjectMapper();
      JsonNode jsonNode = mapper.readTree(query);
      
      // Check if aggs is incorrectly placed inside query
      if (jsonNode.has("query")) {
        JsonNode queryNode = jsonNode.get("query");
        
        // Fix: Move aggs from inside query to root level
        if (queryNode.has("aggs")) {
          JsonNode aggsNode = queryNode.get("aggs");
          
          // Create a new root object with aggs moved out
          ObjectNode fixedQuery = mapper.createObjectNode();
          fixedQuery.set("query", queryNode.deepCopy());
          fixedQuery.remove("aggs"); // Remove aggs from query
          fixedQuery.set("aggs", aggsNode);
          
          // Copy other root-level fields
          jsonNode.fieldNames().forEachRemaining(fieldName -> {
            if (!fieldName.equals("query") && !fieldName.equals("aggs")) {
              fixedQuery.set(fieldName, jsonNode.get(fieldName));
            }
          });
          
          String fixedQueryString = mapper.writeValueAsString(fixedQuery);
          System.out.println("[AiServiceImpl] Fixed query structure - moved aggs to root level");
          return fixedQueryString;
        }
        
        // Fix: Move aggs from inside bool to root level
        if (queryNode.has("bool")) {
          JsonNode boolNode = queryNode.get("bool");
          if (boolNode.has("aggs")) {
            JsonNode aggsNode = boolNode.get("aggs");
            
            // Create a new root object with aggs moved out
            ObjectNode fixedQuery = mapper.createObjectNode();
            ObjectNode newQueryNode = queryNode.deepCopy();
            ObjectNode newBoolNode = boolNode.deepCopy();
            newBoolNode.remove("aggs");
            newQueryNode.set("bool", newBoolNode);
            fixedQuery.set("query", newQueryNode);
            fixedQuery.set("aggs", aggsNode);
            
            // Copy other root-level fields
            jsonNode.fieldNames().forEachRemaining(fieldName -> {
              if (!fieldName.equals("query") && !fieldName.equals("aggs")) {
                fixedQuery.set(fieldName, jsonNode.get(fieldName));
              }
            });
            
            String fixedQueryString = mapper.writeValueAsString(fixedQuery);
            System.out.println("[AiServiceImpl] Fixed query structure - moved aggs from bool to root level");
            return fixedQueryString;
          }
        }
      }
      
      return query; // No fixes needed
      
    } catch (Exception e) {
      System.out.println("[AiServiceImpl] Failed to fix query structure: " + e.getMessage());
      return query; // Return original query if fix fails
    }
  }

  /**
   * Create and validate an Elasticsearch DSL query
   * @param queryBody JSON query string
   * @return Map containing validation result and formatted query
   */
  public Map<String, Object> createAndValidateQuery(String queryBody) {
    Map<String, Object> result = new HashMap<>();
    
    try {
      // First try to fix common structure issues
      String fixedQuery = fixQueryStructure(queryBody);
      
      // Validate the query syntax
      String validationError = validateQuerySyntax(fixedQuery);
      
      if (validationError != null) {
        result.put("success", false);
        result.put("error", validationError);
        result.put("query", queryBody);
        result.put("fixed_query", fixedQuery);
        return result;
      }
      
      // Format the query for better readability
      ObjectMapper mapper = new ObjectMapper();
      JsonNode jsonNode = mapper.readTree(fixedQuery);
      String formattedQuery = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(jsonNode);
      
      result.put("success", true);
      result.put("query", fixedQuery);
      result.put("formatted_query", formattedQuery);
      result.put("validation_message", "Query syntax is valid");
      result.put("was_fixed", !fixedQuery.equals(queryBody));
      
    } catch (Exception e) {
      result.put("success", false);
      result.put("error", "Failed to process query: " + e.getMessage());
      result.put("query", queryBody);
    }
    
    return result;
  }

  /**
   * T√≥m t·∫Øt v√† di·ªÖn gi·∫£i d·ªØ li·ªáu log th√†nh ng√¥n ng·ªØ t·ª± nhi√™n
   * S·ª≠ d·ª•ng AI ƒë·ªÉ ph√¢n t√≠ch k·∫øt qu·∫£ t·ª´ Elasticsearch v√† t·∫°o c√¢u tr·∫£ l·ªùi d·ªÖ hi·ªÉu
   *
   * @param sessionId ID phi√™n chat ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh
   * @param chatRequest Y√™u c·∫ßu g·ªëc t·ª´ ng∆∞·ªùi d√πng
   * @param content D·ªØ li·ªáu log t·ª´ Elasticsearch ho·∫∑c c√¢u tr·∫£ l·ªùi tr·ª±c ti·∫øp
   * @param query Query ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t√¨m ki·∫øm
   * @return C√¢u tr·∫£ l·ªùi b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n
   */
  public String getAiResponse(Long sessionId,ChatRequest chatRequest, String content,String query) {
    String conversationId = sessionId.toString();

    // L·∫•y th·ªùi gian th·ª±c c·ªßa m√°y
    LocalDateTime currentTime = LocalDateTime.now();
    String currentDate = currentTime.format(DateTimeFormatter.ofPattern("yyyy-MM-dd"));
    String currentDateTime = currentTime.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));

    // ƒê·ªãnh d·∫°ng JSON query ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n
    String formattedQuery = query;
    try {
      ObjectMapper mapper = new ObjectMapper();
      JsonNode jsonNode = mapper.readTree(query);
      formattedQuery = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(jsonNode);
    } catch (Exception e) {
      System.out.println("[AiServiceImpl] Could not format query JSON: " + e.getMessage());
    }

    // T·∫°o system message h∆∞·ªõng d·∫´n AI c√°ch ph·∫£n h·ªìi
    SystemMessage systemMessage = new SystemMessage(String.format("""
                You are HPT.AI
                You should respond in a formal voice.

                IMPORTANT CONTEXT:
                - Current date: %s
                - Current datetime: %s (Vietnam timezone +07:00)
                - All dates in the query and data are valid and current
                - NEVER mention that dates are "in the future" or incorrect
                - NEVER reference 2023 or any other year as current time

                IMPORTANT: Always include the Elasticsearch query used at the end of your response.
                Also include a short justification for key field choices.
                CRITICAL: If the user asks for counts (ƒë·∫øm/s·ªë l∆∞·ª£ng) or totals (t·ªïng), you MUST parse Elasticsearch aggregations and state the numeric answer clearly.

                DATA INTERPRETATION RULES:
                - FIRST: Check if there is ANY data in the response. Look for aggregations with values > 0 OR hits with entries.
                - If aggregations.total_count.value > 0, there IS data - report the count (e.g., "S·ªë log: 1234").
                - If aggregations.total_bytes.value > 0, there IS data - report the total (e.g., "T·ªïng bytes: 56789").
                - If hits.total.value > 0 OR hits.hits array has entries, there IS data - summarize the logs naturally.
                - ONLY say "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu" if BOTH aggregations are empty/zero AND hits.total.value = 0 AND hits.hits is empty array.
                - DO NOT say no data just because size=0 - aggregations can still have results.
                - If aggregations exist with non-zero values, ALWAYS report them as the answer.
                - If query has "aggs" but no "query", it's an aggregation query - base answer on aggregations only.
                - If both aggregations and hits exist, prioritize aggregations for counts/totals, use hits for details.
                - IMPORTANT: For queries that return hits with data (hits.total.value > 0), ALWAYS summarize the log entries, never say no data.
                - CRITICAL: In the provided content, if you see hits.total.value > 0 and hits.hits array with entries, there IS data - summarize it.
                - ABSOLUTE RULE: If hits.total.value is greater than 0 (like 10000) and hits.hits contains entries (like 10 entries), there IS DEFINITELY data - summarize the logs.
                - NEVER say "no data" when hits.total.value > 0 and hits.hits has entries.
                - If you see "hits":{"total":{"value":10000},"hits":[{...},{...},...]} then there IS data - summarize it.

                NO DATA SCENARIOS (only when truly empty):
                - hits.total.value = 0 AND hits.hits = [] AND no aggregations with values > 0
                - aggregations.total_count.value = 0 AND no other aggregation values > 0

                LOG DATA EXTRACTION RULES:
                For each log entry in hits.hits, extract and display these key fields when available:
                - Ng∆∞·ªùi d√πng: source.user.name (if available)
                - ƒê·ªãa ch·ªâ ngu·ªìn: source.ip
                - ƒê·ªãa ch·ªâ ƒë√≠ch: destination.ip
                - H√†nh ƒë·ªông: fortinet.firewall.action (allow/deny) or event.action
                - N·ªôi dung: event.message or log.message or message
                - Th·ªùi gian: @timestamp (format as readable date)
                - Rule: rule.name (if available)
                - Port ƒë√≠ch: destination.port (if available)
                - Protocol: network.protocol (if available)
                - Bytes: network.bytes (if available)
                - Qu·ªëc gia ngu·ªìn: source.geo.country_name (if available)
                - Qu·ªëc gia ƒë√≠ch: destination.geo.country_name (if available)
                - M·ª©c r·ªßi ro: fortinet.firewall.crlevel (if available)
                - T·∫•n c√¥ng: fortinet.firewall.attack (if available)

                logData : %s
                query : %s

                Format your response as:
                [Your analysis and summary of the data based on current date %s]

                LOG INFORMATION PRESENTATION:
                Present log information in a natural, descriptive format. For each log entry, write a clear description that includes the key details:

                Format each log entry as a natural description like:
                "V√†o l√∫c [time], t·ª´ ƒë·ªãa ch·ªâ [source.ip] ƒë√£ [action] k·∫øt n·ªëi ƒë·∫øn [destination.ip]:[port] s·ª≠ d·ª•ng giao th·ª©c [protocol]. Rule ƒë∆∞·ª£c √°p d·ª•ng: [rule.name]. D·ªØ li·ªáu truy·ªÅn t·∫£i: [bytes] bytes."

                Include additional details when available:
                - If source.user.name exists: "Ng∆∞·ªùi d√πng: [source.user.name]"
                - If event.message exists: "M√¥ t·∫£: [event.message]"
                - If geo information exists: "T·ª´ qu·ªëc gia [source.geo.country_name] ƒë·∫øn [destination.geo.country_name]"
                - If risk level exists: "M·ª©c r·ªßi ro: [fortinet.firewall.crlevel]"
                - If attack signature exists: "C·∫£nh b√°o t·∫•n c√¥ng: [fortinet.firewall.attack]"

                Present multiple entries in a flowing narrative style, grouping similar activities when appropriate.

                When the question requests:
                - "ƒë·∫øm s·ªë log ..." ‚Üí Output: "S·ªë log: <number>" (derived from aggregations.total_count.value)
                - "t·ªïng log ..." (t·ªïng s·ªë b·∫£n ghi) ‚Üí Output: "T·ªïng log: <number>" (also aggregations.total_count.value)
                - "t·ªïng bytes/packets ..." ‚Üí Output: "T·ªïng bytes/packets: <number>" (from aggregations.total_bytes/total_packets.value)

                Field Selection Rationale (concise):
                - Explain why the chosen fields best match the intent, referencing categories when relevant
                - Prefer reasons like: action semantics (fortinet.firewall.action vs event.outcome), traffic volume (network.bytes/packets), direction (network.direction), geo (source/destination.geo.country_name), rule grouping (rule.name vs ruleid), user specificity (source.user.* vs user.*)
                - 3-6 bullets max

                **Elasticsearch Query Used:**
                ```json
                %s
                ```
                """
        ,currentDate, currentDateTime, content, query, currentDate, formattedQuery));

    UserMessage userMessage = new UserMessage(chatRequest.message());
    Prompt prompt = new Prompt(systemMessage, userMessage);

    // G·ªçi AI v·ªõi ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ t·∫°o ph·∫£n h·ªìi
    // Provider: default ChatClient (OpenAI) for final response generation
    return chatClient
        .prompt(prompt)
        // OpenAI temperature kept at 0.0 for deterministic responses
        .options(ChatOptions.builder().temperature(0.0D).build())
        .advisors(advisorSpec -> advisorSpec.param(
            ChatMemory.CONVERSATION_ID, conversationId
        ))
        .call()
        .content();
  }

  /**
   * Phi√™n b·∫£n ƒë·∫∑c bi·ªát c·ªßa getAiResponse d√†nh cho comparison mode
   * S·ª≠ d·ª•ng conversationId t√πy ch·ªânh ƒë·ªÉ tr√°nh memory contamination gi·ªØa c√°c model
   * 
   * @param conversationId Conversation ID t√πy ch·ªânh (v√≠ d·ª•: "39_openai", "39_openrouter")
   * @param chatRequest Y√™u c·∫ßu g·ªëc t·ª´ user
   * @param content D·ªØ li·ªáu t·ª´ Elasticsearch
   * @param query Query Elasticsearch ƒë√£ s·ª≠ d·ª•ng
   * @return Ph·∫£n h·ªìi t·ª´ AI
   */
  public String getAiResponseForComparison(String conversationId, ChatRequest chatRequest, String content, String query) {
    // L·∫•y th·ªùi gian th·ª±c c·ªßa m√°y
    LocalDateTime currentTime = LocalDateTime.now();
    String currentDate = currentTime.format(DateTimeFormatter.ofPattern("yyyy-MM-dd"));
    String currentDateTime = currentTime.format(DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss"));

    // ƒê·ªãnh d·∫°ng JSON query ƒë·ªÉ hi·ªÉn th·ªã t·ªët h∆°n
    String formattedQuery = query;
    try {
      ObjectMapper mapper = new ObjectMapper();
      JsonNode jsonNode = mapper.readTree(query);
      formattedQuery = mapper.writerWithDefaultPrettyPrinter().writeValueAsString(jsonNode);
    } catch (Exception e) {
      System.out.println("[AiServiceImpl] Could not format query JSON: " + e.getMessage());
    }
      System.out.println("[AiServiceImpl] n·ªôi dung content: " + content);
    // T·∫°o system message h∆∞·ªõng d·∫´n AI c√°ch ph·∫£n h·ªìi
    SystemMessage systemMessage = new SystemMessage(String.format("""
                You are HPT.AI
                You should respond in a formal voice.
                
                IMPORTANT CONTEXT:
                - Current date: %s
                - Current datetime: %s (Vietnam timezone +07:00)
                - All dates in the query and data are valid and current
                - NEVER mention that dates are "in the future" or incorrect
                - NEVER reference 2023 or any other year as current time
                
                IMPORTANT: Always include the Elasticsearch query used at the end of your response.
                Also include a short justification for key field choices.
                CRITICAL: If the user asks for counts (ƒë·∫øm/s·ªë l∆∞·ª£ng) or totals (t·ªïng), you MUST parse Elasticsearch aggregations and state the numeric answer clearly.
                
                DATA INTERPRETATION RULES:
                - FIRST: Check if there is ANY data in the response. Look for aggregations with values > 0 OR hits with entries.
                - If aggregations.total_count.value > 0, there IS data - report the count (e.g., "S·ªë log: 1234").
                - If aggregations.total_bytes.value > 0, there IS data - report the total (e.g., "T·ªïng bytes: 56789").
                - If hits.total.value > 0 OR hits.hits array has entries, there IS data - summarize the logs naturally.
                - ONLY say "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu" if BOTH aggregations are empty/zero AND hits.total.value = 0 AND hits.hits is empty array.
                - DO NOT say no data just because size=0 - aggregations can still have results.
                - If aggregations exist with non-zero values, ALWAYS report them as the answer.
                - If query has "aggs" but no "query", it's an aggregation query - base answer on aggregations only.
                - If both aggregations and hits exist, prioritize aggregations for counts/totals, use hits for details.
                - IMPORTANT: For queries that return hits with data (hits.total.value > 0), ALWAYS summarize the log entries, never say no data.
                - CRITICAL: In the provided content, if you see hits.total.value > 0 and hits.hits array with entries, there IS data - summarize it.
                - ABSOLUTE RULE: If hits.total.value is greater than 0 (like 10000) and hits.hits contains entries (like 10 entries), there IS DEFINITELY data - summarize the logs.
                - NEVER say "no data" when hits.total.value > 0 and hits.hits has entries.
                - If you see "hits":{"total":{"value":10000},"hits":[{...},{...},...]} then there IS data - summarize it.
                
                NO DATA HANDLING:
                When hits.total.value = 0 or aggregations return empty buckets or zero count:
                - Inform the user that no data was found matching their criteria
                - Suggest possible reasons why no data was found
                - Suggest possible modifications to the query
                - DO NOT use a fixed format, respond naturally
                
                EXAMPLES OF NO DATA SCENARIOS:
                - {"hits":{"total":{"value":0},"hits":[]}} ‚Üí No matching documents
                - {"aggregations":{"total_count":{"value":0}}} ‚Üí Count is zero
                - {"aggregations":{"top_users":{"buckets":[]}}} ‚Üí No aggregation results
                - Empty aggregation buckets = no matching data found
                
                LOG DATA EXTRACTION RULES:
                For each log entry in hits.hits, extract and display these key fields when available:
                - Ng∆∞·ªùi d√πng: source.user.name (if available)
                - ƒê·ªãa ch·ªâ ngu·ªìn: source.ip 
                - ƒê·ªãa ch·ªâ ƒë√≠ch: destination.ip
                - H√†nh ƒë·ªông: fortinet.firewall.action (allow/deny) or event.action
                - N·ªôi dung: event.message or log.message or message
                - Th·ªùi gian: @timestamp (format as readable date)
                - Rule: rule.name (if available)
                - Port ƒë√≠ch: destination.port (if available)
                - Protocol: network.protocol (if available)
                - Bytes: network.bytes (if available)
                - Qu·ªëc gia ngu·ªìn: source.geo.country_name (if available)
                - Qu·ªëc gia ƒë√≠ch: destination.geo.country_name (if available)
                - M·ª©c r·ªßi ro: fortinet.firewall.crlevel (if available)
                - T·∫•n c√¥ng: fortinet.firewall.attack (if available)
                - N·∫øu fortinet.firewall.cfgattr t·ªìn t·∫°i ho·∫∑c c√¢u h·ªèi li√™n quan ƒë·∫øn CNHN_ZONE/cfgattr:
                  ‚Ä¢ QUERY PATTERN: {"query":{"bool":{"filter":[{"term":{"source.user.name":"tanln"}},{"match":{"message":"CNHN_ZONE"}}]}},"sort":[{"@timestamp":"asc"}],"size":200}
                  ‚Ä¢ Ph√¢n t√≠ch chu·ªói cfgattr theo quy t·∫Øc:
                    1) T√°ch hai ph·∫ßn tr∆∞·ªõc v√† sau "->" th√†nh hai danh s√°ch
                    2) Tr∆∞·ªõc khi t√°ch, lo·∫°i b·ªè ti·ªÅn t·ªë "interface[" (n·∫øu c√≥) v√† d·∫•u "]" ·ªü cu·ªëi (n·∫øu c√≥)
                    3) M·ªói danh s√°ch t√°ch ti·∫øp b·∫±ng d·∫•u ph·∫©y ho·∫∑c kho·∫£ng tr·∫Øng, chu·∫©n h√≥a v√† lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a
                    4) "Th√™m" = c√°c gi√° tr·ªã c√≥ trong danh s√°ch m·ªõi nh∆∞ng kh√¥ng c√≥ trong danh s√°ch c≈©
                    5) "X√≥a" = c√°c gi√° tr·ªã c√≥ trong danh s√°ch c≈© nh∆∞ng kh√¥ng c√≥ trong danh s√°ch m·ªõi
                    
                    V√ç D·ª§ PH√ÇN T√çCH:
                    Input: "interface[LAB-CNHN MGMT-SW-FW PRINTER-DEVICE SECCAM-CNHN WiFi HPT-GUEST WiFi-HPTVIETNAM WiFi-IoT SERVER_CORE CNHN_Wire_NV CNHN_Wire_Lab->LAB-CNHN MGMT-SW-FW PRINTER-DEVICE SECCAM-CNHN WiFi HPT-GUEST WiFi-HPTVIETNAM WiFi-IoT SERVER_CORE CNHN_Wire_NV]"
                    
                    B∆∞·ªõc 1: T√°ch b·∫±ng "->"
                    - Tr∆∞·ªõc: "[LAB-CNHN MGMT-SW-FW PRINTER-DEVICE SECCAM-CNHN WiFi HPT-GUEST WiFi-HPTVIETNAM WiFi-IoT SERVER_CORE CNHN_Wire_NV CNHN_Wire_Lab"
                    - Sau: "LAB-CNHN MGMT-SW-FW PRINTER-DEVICE SECCAM-CNHN WiFi HPT-GUEST WiFi-HPTVIETNAM WiFi-IoT SERVER_CORE CNHN_Wire_NV]"
                    
                    B∆∞·ªõc 2: B·ªè ti·ªÅn t·ªë "interface[" v√† d·∫•u "]" r·ªìi t√°ch t·ª´ng danh s√°ch b·∫±ng kho·∫£ng tr·∫Øng
                    - Ban ƒë·∫ßu: LAB-CNHN, MGMT-SW-FW, PRINTER-DEVICE, SECCAM-CNHN, WiFi, HPT-GUEST, WiFi-HPTVIETNAM, WiFi-IoT, SERVER_CORE, CNHN_Wire_NV, CNHN_Wire_Lab]
                    - Sau: LAB-CNHN, MGMT-SW-FW, PRINTER-DEVICE, SECCAM-CNHN, WiFi, HPT-GUEST, WiFi-HPTVIETNAM, WiFi-IoT, SERVER_CORE, CNHN_Wire_NV
                    
                    B∆∞·ªõc 3: So s√°nh
                    - Th√™m: [] (kh√¥ng c√≥)
                    - X√≥a: [CNHN_Wire_Lab]
                  ‚Ä¢ Xu·∫•t theo timeline (s·∫Øp x·∫øp theo @timestamp):
                    - Th·ªùi gian: [@timestamp]
                    - Ng∆∞·ªùi d√πng: [source.user.name]
                    - IP: [source.ip]
                    - H√†nh ƒë·ªông: [message]
                    - Ban ƒë·∫ßu: [...]
                    - Sau: [...]
                    - Th√™m: [...]
                    - X√≥a: [...]
                    Lu√¥n lu√¥n hi·ªÉn th·ªã c·∫£ Ban ƒë·∫ßu v√† Sau, ngay c·∫£ khi kh√¥ng c√≥ s·ª± thay ƒë·ªïi.
                  ‚Ä¢ N·∫øu kh√¥ng c√≥ "->" trong cfgattr, coi to√†n b·ªô l√† danh s√°ch hi·ªán t·∫°i
                logData : %s
                query : %s
                
                Format your response as:
                [Your analysis and summary of the data based on current date %s]
                
                LOG INFORMATION PRESENTATION:
                Present log information in a natural, descriptive format. For each log entry, write a clear description that includes the key details:
                
                Format each log entry as a natural description like:
                "V√†o l√∫c [time], t·ª´ ƒë·ªãa ch·ªâ [source.ip] ƒë√£ [action] k·∫øt n·ªëi ƒë·∫øn [destination.ip]:[port] s·ª≠ d·ª•ng giao th·ª©c [protocol]. Rule ƒë∆∞·ª£c √°p d·ª•ng: [rule.name]. D·ªØ li·ªáu truy·ªÅn t·∫£i: [bytes] bytes."
                
                Include additional details when available:
                - If source.user.name exists: "Ng∆∞·ªùi d√πng: [source.user.name]"
                - If event.message exists: "M√¥ t·∫£: [event.message]"
                - If geo information exists: "T·ª´ qu·ªëc gia [source.geo.country_name] ƒë·∫øn [destination.geo.country_name]"
                - If risk level exists: "M·ª©c r·ªßi ro: [fortinet.firewall.crlevel]"
                - If attack signature exists: "C·∫£nh b√°o t·∫•n c√¥ng: [fortinet.firewall.attack]"
                
                Present multiple entries in a flowing narrative style, grouping similar activities when appropriate.
                
                When the question requests:
                - "ƒë·∫øm s·ªë log ..." ‚Üí Output: "S·ªë log: <number>" (derived from aggregations.total_count.value)
                - "t·ªïng log ..." (t·ªïng s·ªë b·∫£n ghi) ‚Üí Output: "T·ªïng log: <number>" (also aggregations.total_count.value)
                - "t·ªïng bytes/packets ..." ‚Üí Output: "T·ªïng bytes/packets: <number>" (from aggregations.total_bytes/total_packets.value)
                
                Field Selection Rationale (concise):
                - Explain why the chosen fields best match the intent, referencing categories when relevant
                - Prefer reasons like: action semantics (fortinet.firewall.action vs event.outcome), traffic volume (network.bytes/packets), direction (network.direction), geo (source/destination.geo.country_name), rule grouping (rule.name vs ruleid), user specificity (source.user.* vs user.*)
                - 3-6 bullets max
                
                **Elasticsearch Query Used:**
                ```json
                %s
                ```
                """
        ,currentDate, currentDateTime, content, query, currentDate, formattedQuery));

    UserMessage userMessage = new UserMessage(chatRequest.message());
    Prompt prompt = new Prompt(systemMessage, userMessage);
    // G·ªçi AI v·ªõi conversation ID t√πy ch·ªânh ƒë·ªÉ tr√°nh memory contamination
    // Provider: default ChatClient (OpenAI) for comparison response generation
    return chatClient
        .prompt(prompt)
        // OpenAI temperature kept at 0.0 for deterministic responses
        .options(ChatOptions.builder().temperature(0.0D).build())
        .advisors(advisorSpec -> advisorSpec.param(
            ChatMemory.CONVERSATION_ID, conversationId
        ))
        .call()
        .content();
  }

  /**
   * X·ª≠ l√Ω y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng trong ch·∫ø ƒë·ªô so s√°nh, s·ª≠ d·ª•ng c·∫£ OpenAI v√† OpenRouter
   * @param sessionId ID phi√™n chat ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh
   * @param chatRequest Y√™u c·∫ßu t·ª´ ng∆∞·ªùi d√πng
   * @return K·∫øt qu·∫£ so s√°nh gi·ªØa hai provider
   */
  @Override
  public Map<String, Object> handleRequestWithComparison(Long sessionId, ChatRequest chatRequest) {
    Map<String, Object> result = new HashMap<>();
    LocalDateTime now = LocalDateTime.now();
    String dateContext = generateDateContext(now);
    
    try {
      System.out.println("[AiServiceImpl] ===== B·∫ÆT ƒê·∫¶U CH·∫æ ƒê·ªò SO S√ÅNH =====");
      System.out.println("[AiServiceImpl] B·∫Øt ƒë·∫ßu ch·∫ø ƒë·ªô so s√°nh cho phi√™n: " + sessionId);
      System.out.println("[AiServiceImpl] Tin nh·∫Øn ng∆∞·ªùi d√πng: " + chatRequest.message());
      System.out.println("[AiServiceImpl] S·ª≠ d·ª•ng ng·ªØ c·∫£nh ng√†y th√°ng: " + now.format(DateTimeFormatter.ofPattern("yyyy-MM-dd")));
      
      // --- B∆Ø·ªöC 1: So s√°nh qu√° tr√¨nh t·∫°o query ---
      System.out.println("[AiServiceImpl] ===== B∆Ø·ªöC 1: T·∫°o Elasticsearch Query =====");
      
      // Chu·∫©n b·ªã schema m·ªôt l·∫ßn ƒë·ªÉ d√πng l·∫°i cho c·∫£ hai prompt
      String fullSchema = SchemaHint.getSchemaHint();
      
      // S·ª≠ d·ª•ng QueryPromptTemplate: ƒë∆∞a to√†n b·ªô th∆∞ vi·ªán + v√≠ d·ª• ƒë·ªông (n·∫øu c√≥)
      Map<String, Object> dynamicInputs = new HashMap<>();
      String queryPrompt = com.example.chatlog.utils.QueryPromptTemplate.createQueryGenerationPromptWithAllTemplates(
          chatRequest.message(),
          dateContext,
          fullSchema,
          SchemaHint.getRoleNormalizationRules(),
          dynamicInputs
      );
      // System.out.println("[AiServiceImpl] SYSTEM PROMPT (queryPrompt) length=" + queryPrompt.length());
      // System.out.println("[AiServiceImpl] SYSTEM PROMPT (queryPrompt) preview:\n" + queryPrompt);

      // T·∫°o system prompt ƒë·∫ßy ƒë·ªß t·ª´ PromptTemplate v·ªõi to√†n b·ªô SchemaHint ƒë·ªÉ b·ªï sung ng·ªØ c·∫£nh
      String fullSystemPrompt = com.example.chatlog.utils.PromptTemplate.getSystemPrompt(
          dateContext,
          SchemaHint.getRoleNormalizationRules(),
          fullSchema,
          SchemaHint.getCategoryGuides(),
          SchemaHint.getNetworkTrafficExamples(),
          SchemaHint.getIPSSecurityExamples(),
          SchemaHint.getAdminRoleExample(),
          SchemaHint.getGeographicExamples(),
          SchemaHint.getFirewallRuleExamples(),
          SchemaHint.getCountingExamples(),
          SchemaHint.getQuickPatterns()
      );

      // Gh√©p t·∫•t c·∫£ v√†o m·ªôt system message duy nh·∫•t ƒë·ªÉ AI c√≥ t·ªëi ƒëa b·ªëi c·∫£nh
      String combinedPrompt = queryPrompt + "\n\n" + fullSystemPrompt;
      SystemMessage systemMessage = new SystemMessage(combinedPrompt);

      UserMessage userMessage = new UserMessage(chatRequest.message());
      List<String> schemaHints = SchemaHint.allSchemas();
      String schemaContext = String.join("\n\n", schemaHints);
      UserMessage schemaMsg = new UserMessage("Available schema hints:\n" + schemaContext);
      // Provide a single sample log to help AI infer fields and structure
      UserMessage sampleLogMsg = new UserMessage("SAMPLE LOG (for inference):\n" + SchemaHint.examplelog());

      System.out.println("---------------------------------------------------------------------------------------");
      Prompt prompt = new Prompt(List.of(systemMessage, schemaMsg, sampleLogMsg, userMessage));

      ChatOptions chatOptions = ChatOptions.builder()
          .temperature(0.0D)
          .build();
      
      // Theo d√µi th·ªùi gian t·∫°o query c·ªßa OpenAI
      System.out.println("[AiServiceImpl] üîµ OPENAI - ƒêang t·∫°o Elasticsearch query...");
      long openaiStartTime = System.currentTimeMillis();
      RequestBody openaiQuery = chatClient
          .prompt(prompt)
          .options(chatOptions)
          .call()
          .entity(new ParameterizedTypeReference<>() {});
      long openaiEndTime = System.currentTimeMillis();
      
      // ƒê·∫£m b·∫£o gi√° tr·ªã query ƒë∆∞·ª£c ƒë·∫∑t l√† 1
      if (openaiQuery.getQuery() != 1) {
        openaiQuery.setQuery(1);
      }
      
      // S·ª≠a query OpenAI n·∫øu c·∫ßn
      String openaiQueryString = openaiQuery.getBody();
      System.out.println("[AiServiceImpl] ‚úÖ OPENAI - Query ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng trong " + (openaiEndTime - openaiStartTime) + "ms");
      System.out.println("[AiServiceImpl] üìù OPENAI - Query: " + openaiQueryString);
      
      // Theo d√µi th·ªùi gian t·∫°o query c·ªßa OpenRouter (th·ª±c s·ª± g·ªçi OpenRouter v·ªõi temperature kh√°c)
      System.out.println("[AiServiceImpl] üü† OPENROUTER - ƒêang t·∫°o Elasticsearch query...");
      long openrouterStartTime = System.currentTimeMillis();
      
      // Provider: OpenRouter (query generation in comparison mode)
      // Ghi ch√∫: ƒê√¢y l√† c·∫•u h√¨nh temperature d√†nh cho OpenRouter
      ChatOptions openrouterChatOptions = ChatOptions.builder()
          .temperature(0.5D)
          .build();
      
      RequestBody openrouterQuery;
      String openrouterQueryString;
      
      try {
        // G·ªçi tr·ª±c ti·∫øp ChatClient v·ªõi options OpenRouter (openrouterChatOptions)
        openrouterQuery = chatClient
            .prompt(prompt)
            .options(openrouterChatOptions)
            .call()
            .entity(new ParameterizedTypeReference<>() {});
            
        if (openrouterQuery.getQuery() != 1) {
          openrouterQuery.setQuery(1);
        }
        openrouterQueryString = openrouterQuery.getBody();
        
        System.out.println("[AiServiceImpl] ‚úÖ OPENROUTER - Query ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng v·ªõi temperature kh√°c bi·ªát");
      } catch (Exception e) {
        if (e.getMessage() != null && (e.getMessage().contains("503") || e.getMessage().contains("upstream connect error"))) {
          System.out.println("[AiServiceImpl] ‚ö†Ô∏è OPENROUTER - Service t·∫°m th·ªùi kh√¥ng kh·∫£ d·ª•ng (HTTP 503), d√πng l·∫°i query OpenAI: " + e.getMessage());
        } else {
          System.out.println("[AiServiceImpl] ‚ùå OPENROUTER - T·∫°o query th·∫•t b·∫°i, d√πng l·∫°i query OpenAI: " + e.getMessage());
        }
        openrouterQueryString = openaiQueryString; // Fallback to OpenAI query
      }
      
      long openrouterEndTime = System.currentTimeMillis();
      System.out.println("[AiServiceImpl] ‚úÖ OPENROUTER - Query ƒë∆∞·ª£c t·∫°o trong " + (openrouterEndTime - openrouterStartTime) + "ms");
      System.out.println("[AiServiceImpl] üìù OPENROUTER - Query: " + openrouterQueryString);
      
      // L∆∞u tr·ªØ k·∫øt qu·∫£ t·∫°o query
      Map<String, Object> queryGenerationComparison = new HashMap<>();
      
      Map<String, Object> openaiGeneration = new HashMap<>();
      openaiGeneration.put("response_time_ms", openaiEndTime - openaiStartTime);
      openaiGeneration.put("model", ModelProvider.OPENAI.getModelName());
      openaiGeneration.put("query", openaiQueryString);
      
      Map<String, Object> openrouterGeneration = new HashMap<>();
      openrouterGeneration.put("response_time_ms", openrouterEndTime - openrouterStartTime);
      openrouterGeneration.put("model", ModelProvider.OPENROUTER.getModelName());
      openrouterGeneration.put("query", openrouterQueryString);
      
      queryGenerationComparison.put("openai", openaiGeneration);
      queryGenerationComparison.put("openrouter", openrouterGeneration);
      
      // --- B∆Ø·ªöC 2: T√¨m ki·∫øm Elasticsearch ---
      System.out.println("[AiServiceImpl] ===== B∆Ø·ªöC 2: T√¨m ki·∫øm Elasticsearch =====");
      
      // Th·ª±c hi·ªán t√¨m ki·∫øm Elasticsearch v·ªõi c·∫£ hai query
      Map<String, Object> elasticsearchComparison = new HashMap<>();
      
      // T√¨m ki·∫øm OpenAI
      System.out.println("[AiServiceImpl] üîµ OPENAI - ƒêang th·ª±c hi·ªán t√¨m ki·∫øm Elasticsearch...");
        String[] openaiResults = getLogData(openaiQuery, chatRequest);
      String openaiContent = openaiResults[0];
      String finalOpenaiQuery = openaiResults[1];

      // Ki·ªÉm tra n·∫øu c√≥ l·ªói trong qu√° tr√¨nh t√¨m ki·∫øm
      if (openaiContent != null && openaiContent.startsWith("‚ùå")) {
        System.out.println("[AiServiceImpl] ‚ùå OPENAI - T√¨m ki·∫øm Elasticsearch g·∫∑p l·ªói, ƒëang th·ª≠ s·ª≠a query...");
        System.out.println("[AiServiceImpl] üîß OPENAI - ƒêang t·∫°o l·∫°i query v·ªõi th√¥ng tin l·ªói...");
      } else {
        System.out.println("[AiServiceImpl] ‚úÖ OPENAI - T√¨m ki·∫øm Elasticsearch ho√†n th√†nh th√†nh c√¥ng");
        // Hi·ªÉn th·ªã preview d·ªØ li·ªáu tr·∫£ v·ªÅ
        System.out.println("[AiServiceImpl] üìä D·ªÆ LI·ªÜU TR·∫¢ V·ªÄ (OpenAI): " + (openaiContent.length() > 500 ? openaiContent.substring(0, 500) + "..." : openaiContent));
      }
      
      Map<String, Object> openaiElasticsearch = new HashMap<>();
      openaiElasticsearch.put("data", openaiContent);
      openaiElasticsearch.put("success", true);
      openaiElasticsearch.put("query", finalOpenaiQuery);

      System.out.println("OpenaiElasticsearch : "+ openaiElasticsearch);
      
      // N·∫øu OpenAI query th·∫•t b·∫°i ho√†n to√†n, d√πng fallback m·∫´u g·ª£i √Ω t·ª´ QueryTemplates
      if (openaiContent != null && openaiContent.startsWith("‚ùå")) {
        System.out.println("[AiServiceImpl] üîµ OPENAI - D√πng fallback query m·∫´u t·ª´ QueryTemplates.OUTBOUND_PORT_ANALYSIS");
        RequestBody fallbackOpenAi = new RequestBody(QueryTemplates.OUTBOUND_PORT_ANALYSIS, 1);
        String[] fallbackOpenAiResults = getLogData(fallbackOpenAi, chatRequest);
        if (fallbackOpenAiResults[0] != null && !fallbackOpenAiResults[0].startsWith("‚ùå")) {
          openaiContent = fallbackOpenAiResults[0];
          finalOpenaiQuery = fallbackOpenAiResults[1];
          System.out.println("[AiServiceImpl] üîµ OPENAI - Fallback query tr·∫£ v·ªÅ d·ªØ li·ªáu th√†nh c√¥ng");
          // Hi·ªÉn th·ªã preview d·ªØ li·ªáu fallback
          System.out.println("[AiServiceImpl] üìä D·ªÆ LI·ªÜU FALLBACK (OpenAI): " + (openaiContent.length() > 500 ? openaiContent.substring(0, 500) + "..." : openaiContent));
        }
      }

      // T√¨m ki·∫øm OpenRouter (s·ª≠ d·ª•ng query ri√™ng t·ª´ OpenRouter)
      System.out.println("[AiServiceImpl] üü† OPENROUTER - ƒêang th·ª±c hi·ªán t√¨m ki·∫øm Elasticsearch...");
      RequestBody openrouterRequestBody = new RequestBody(openrouterQueryString, 1);
      String[] openrouterResults = getLogData(openrouterRequestBody, chatRequest);
      String openrouterContent = openrouterResults[0];
      String finalOpenrouterQuery = openrouterResults[1];
      
      // Ki·ªÉm tra n·∫øu c√≥ l·ªói trong qu√° tr√¨nh t√¨m ki·∫øm
      if (openrouterContent != null && openrouterContent.startsWith("‚ùå")) {
        System.out.println("[AiServiceImpl] ‚ùå OPENROUTER - T√¨m ki·∫øm Elasticsearch g·∫∑p l·ªói, ƒëang th·ª≠ s·ª≠a query...");
        System.out.println("[AiServiceImpl] üîß OPENROUTER - ƒêang t·∫°o l·∫°i query v·ªõi th√¥ng tin l·ªói...");
      } else {
        System.out.println("[AiServiceImpl] ‚úÖ OPENROUTER - T√¨m ki·∫øm Elasticsearch ho√†n th√†nh th√†nh c√¥ng");
        // Hi·ªÉn th·ªã preview d·ªØ li·ªáu tr·∫£ v·ªÅ
        System.out.println("[AiServiceImpl] üìä D·ªÆ LI·ªÜU TR·∫¢ V·ªÄ (OpenRouter): " + (openrouterContent.length() > 500 ? openrouterContent.substring(0, 500) + "..." : openrouterContent));
      }
      
      Map<String, Object> openrouterElasticsearch = new HashMap<>();
      openrouterElasticsearch.put("data", openrouterContent);
      openrouterElasticsearch.put("success", true);
      openrouterElasticsearch.put("query", finalOpenrouterQuery);

      System.out.println("OpenrouterElasticsearch : " + openrouterElasticsearch);

      // N·∫øu OpenRouter c≈©ng th·∫•t b·∫°i, th·ª≠ fallback t∆∞∆°ng t·ª±
      if (openrouterContent != null && openrouterContent.startsWith("‚ùå")) {
        System.out.println("[AiServiceImpl] üü† OPENROUTER - D√πng fallback query m·∫´u t·ª´ QueryTemplates.OUTBOUND_PORT_ANALYSIS");
        RequestBody fallbackOpenrouter = new RequestBody(QueryTemplates.OUTBOUND_PORT_ANALYSIS, 1);
        String[] fallbackOpenrouterResults = getLogData(fallbackOpenrouter, chatRequest);
        if (fallbackOpenrouterResults[0] != null && !fallbackOpenrouterResults[0].startsWith("‚ùå")) {
          openrouterContent = fallbackOpenrouterResults[0];
          finalOpenrouterQuery = fallbackOpenrouterResults[1];
          System.out.println("[AiServiceImpl] üü† OPENROUTER - Fallback query tr·∫£ v·ªÅ d·ªØ li·ªáu th√†nh c√¥ng");
          // Hi·ªÉn th·ªã preview d·ªØ li·ªáu fallback
          System.out.println("[AiServiceImpl] üìä D·ªÆ LI·ªÜU FALLBACK (OpenRouter): " + (openrouterContent.length() > 500 ? openrouterContent.substring(0, 500) + "..." : openrouterContent));
        }
      }

      elasticsearchComparison.put("openai", openaiElasticsearch);
      elasticsearchComparison.put("openrouter", openrouterElasticsearch);
      
      // --- B∆Ø·ªöC 3: T·∫°o c√¢u tr·∫£ l·ªùi ---
      System.out.println("[AiServiceImpl] ===== B∆Ø·ªöC 3: T·∫°o c√¢u tr·∫£ l·ªùi AI =====");
      
      // T·∫°o c√¢u tr·∫£ l·ªùi t·ª´ c·∫£ hai model
      Map<String, Object> responseGenerationComparison = new HashMap<>();
      
      // C√¢u tr·∫£ l·ªùi t·ª´ OpenAI
      System.out.println("[AiServiceImpl] üîµ OPENAI - ƒêang t·∫°o ph·∫£n h·ªìi t·ª´ d·ªØ li·ªáu Elasticsearch...");
      long openaiResponseStartTime = System.currentTimeMillis();
      String openaiResponse = getAiResponseForComparison(sessionId + "_openai", chatRequest, openaiContent, finalOpenaiQuery);
      long openaiResponseEndTime = System.currentTimeMillis();
      System.out.println("[AiServiceImpl] ‚úÖ OPENAI - Ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng trong " + (openaiResponseEndTime - openaiResponseStartTime) + "ms");
      
      Map<String, Object> openaiResponseData = new HashMap<>();
      openaiResponseData.put("elasticsearch_query", finalOpenaiQuery);
      openaiResponseData.put("response", openaiResponse);
      openaiResponseData.put("model", ModelProvider.OPENAI.getModelName());
      openaiResponseData.put("elasticsearch_data", openaiContent);
      openaiResponseData.put("response_time_ms", openaiResponseEndTime - openaiResponseStartTime);
      
      // C√¢u tr·∫£ l·ªùi t·ª´ OpenRouter (s·ª≠ d·ª•ng d·ªØ li·ªáu ri√™ng t·ª´ OpenRouter query)
      System.out.println("[AiServiceImpl] üü† OPENROUTER - ƒêang t·∫°o ph·∫£n h·ªìi t·ª´ d·ªØ li·ªáu Elasticsearch...");
      long openrouterResponseStartTime = System.currentTimeMillis();
      String openrouterResponse = getAiResponseForComparison(sessionId + "_openrouter", chatRequest, openrouterContent, finalOpenrouterQuery);
      long openrouterResponseEndTime = System.currentTimeMillis();
      System.out.println("[AiServiceImpl] ‚úÖ OPENROUTER - Ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng trong " + (openrouterResponseEndTime - openrouterResponseStartTime) + "ms");
      
      Map<String, Object> openrouterResponseData = new HashMap<>();
      openrouterResponseData.put("elasticsearch_query", finalOpenrouterQuery);
      openrouterResponseData.put("response", openrouterResponse);
      openrouterResponseData.put("model", ModelProvider.OPENROUTER.getModelName());
      openrouterResponseData.put("elasticsearch_data", openrouterContent);
      openrouterResponseData.put("response_time_ms", openrouterResponseEndTime - openrouterResponseStartTime);
      
      responseGenerationComparison.put("openai", openaiResponseData);
      responseGenerationComparison.put("openrouter", openrouterResponseData);
      
      // --- T·ªïng h·ª£p k·∫øt qu·∫£ cu·ªëi c√πng ---
      System.out.println("[AiServiceImpl] ===== T·ªîNG H·ª¢P K·∫æT QU·∫¢ =====");
      
      result.put("elasticsearch_comparison", elasticsearchComparison);
      result.put("success", true);
      result.put("query_generation_comparison", queryGenerationComparison);
      result.put("response_generation_comparison", responseGenerationComparison);
      result.put("timestamp", now.toString());
      result.put("user_question", chatRequest.message());
      
      System.out.println("[AiServiceImpl] üéâ So s√°nh ho√†n th√†nh th√†nh c√¥ng!");
      System.out.println("[AiServiceImpl] ‚è±Ô∏è T·ªïng th·ªùi gian OpenAI: " + (openaiEndTime - openaiStartTime + openaiResponseEndTime - openaiResponseStartTime) + "ms");
      System.out.println("[AiServiceImpl] ‚è±Ô∏è T·ªïng th·ªùi gian OpenRouter: " + (openrouterEndTime - openrouterStartTime + openrouterResponseEndTime - openrouterResponseStartTime) + "ms");
      System.out.println("[AiServiceImpl] üîç S·ª± kh√°c bi·ªát query OpenAI vs OpenRouter: " + (!openaiQueryString.equals(openrouterQueryString) ? "C√°c query kh√°c nhau ƒë∆∞·ª£c t·∫°o" : "C√πng query ƒë∆∞·ª£c t·∫°o"));
      System.out.println("[AiServiceImpl] üìä S·ª± kh√°c bi·ªát d·ªØ li·ªáu OpenAI vs OpenRouter: " + (!openaiContent.equals(openrouterContent) ? "D·ªØ li·ªáu kh√°c nhau ƒë∆∞·ª£c truy xu·∫•t" : "C√πng d·ªØ li·ªáu ƒë∆∞·ª£c truy xu·∫•t"));
      
    } catch (Exception e) {
      System.out.println("[AiServiceImpl] ‚ùå ===== L·ªñI TRONG CH·∫æ ƒê·ªò SO S√ÅNH =====");
      System.out.println("[AiServiceImpl] üí• L·ªói trong ch·∫ø ƒë·ªô so s√°nh: " + e.getMessage());
      e.printStackTrace();
      
      result.put("success", false);
      result.put("error", e.getMessage());
      result.put("timestamp", now.toString());
    }
    
    return result;
  }
}